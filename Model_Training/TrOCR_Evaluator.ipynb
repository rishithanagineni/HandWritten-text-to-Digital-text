{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vEP0Q4kwCYz",
        "outputId": "de369ab3-034a-4767-b0a5-657d710ad9e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m471.0/480.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets jiwer evaluate transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9zTKtweJwQrW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi-2Ehw1wULx",
        "outputId": "6ea36b2a-0cbd-4cb2-c11b-91443d676a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DspS68hgwXfn",
        "outputId": "cde5b428-54a3-4850-bcd3-5bc9b3d1f33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found '/drive/MyDrive/Comp 542/IAM/evaluation_df.csv' on Google Drive.\n",
            "                                              file_name     text bin_category  \\\n",
            "0     /drive/MyDrive/Comp 542/IAM/words/h07/h07-037/...       to   very short   \n",
            "1     /drive/MyDrive/Comp 542/IAM/words/r06/r06-027/...        ,   very short   \n",
            "2     /drive/MyDrive/Comp 542/IAM/words/b01/b01-000/...    issue        short   \n",
            "3     /drive/MyDrive/Comp 542/IAM/words/f07/f07-039b...       in   very short   \n",
            "4     /drive/MyDrive/Comp 542/IAM/words/p01/p01-174/...      led   very short   \n",
            "...                                                 ...      ...          ...   \n",
            "9061  /drive/MyDrive/Comp 542/IAM/words/c06/c06-043/...  seizure        short   \n",
            "9062  /drive/MyDrive/Comp 542/IAM/words/e04/e04-103/...    third        short   \n",
            "9063  /drive/MyDrive/Comp 542/IAM/words/g04/g04-011/...     been   very short   \n",
            "9064  /drive/MyDrive/Comp 542/IAM/words/r06/r06-130/...        ,   very short   \n",
            "9065  /drive/MyDrive/Comp 542/IAM/words/a02/a02-111/...     back   very short   \n",
            "\n",
            "      normalized_length  \n",
            "0                 0.125  \n",
            "1                 0.000  \n",
            "2                 0.500  \n",
            "3                 0.125  \n",
            "4                 0.250  \n",
            "...                 ...  \n",
            "9061              0.750  \n",
            "9062              0.500  \n",
            "9063              0.375  \n",
            "9064              0.000  \n",
            "9065              0.375  \n",
            "\n",
            "[9066 rows x 4 columns]\n",
            "Amount of test samples 9066\n"
          ]
        }
      ],
      "source": [
        "dataset_path = '/drive/MyDrive/Comp 542/IAM/'\n",
        "test_set_file_path = os.path.join(dataset_path,'evaluation_df.csv')\n",
        "\n",
        "if os.path.exists(test_set_file_path):\n",
        "  print(f\"Found '{test_set_file_path}' on Google Drive.\")\n",
        "  test_df = pd.read_csv(test_set_file_path, sep=',')\n",
        "  test_df.rename(columns={'file_path': \"file_name\", 'label': \"text\"}, inplace=True)\n",
        "else:\n",
        "  print(f\"Waring '{test_set_file_path}' does not exist on Google Drive.\")\n",
        "  print(f\"Creating a local csv upload to google drive\")\n",
        "\n",
        "  data_set_file_path= os.path.join(dataset_path,'dataset.csv')\n",
        "  df = pd.read_csv(data_set_file_path, sep=',')\n",
        "  df.rename(columns={'file_path': \"file_name\", 'label': \"text\"}, inplace=True)\n",
        "\n",
        "  train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "  train_df.reset_index(drop=True, inplace=True)\n",
        "  train_df.to_csv(\"training_df.csv\", index=False)\n",
        "  test_df.reset_index(drop=True, inplace=True)\n",
        "  test_df.to_csv(\"evaluation_df.csv\", index=False)\n",
        "\n",
        "print(test_df)\n",
        "print(f\"Amount of test samples {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lbB039DgwhmC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "          # get file name + text\n",
        "          file_name = self.df['file_name'][idx]\n",
        "          text = self.df['text'][idx]\n",
        "          # prepare image (i.e. resize + normalize)\n",
        "          image = Image.open(file_name).convert(\"RGB\")\n",
        "          pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "          # add labels (input_ids) by encoding the text\n",
        "          labels = self.processor.tokenizer(text,\n",
        "                                            padding=\"max_length\",\n",
        "                                            max_length=self.max_target_length).input_ids\n",
        "          # important: make sure that PAD tokens are ignored by the loss function\n",
        "          labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "          encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
        "        except:\n",
        "          # in case there is an issue loading an image use the last image\n",
        "          return self.__getitem__(idx-1)\n",
        "        return encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QdRuXANRwmsL"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    cer_metric = load(\"cer\")\n",
        "\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    precision = compute_precision(pred_str, label_str)\n",
        "    recall = compute_recall(pred_str, label_str)\n",
        "\n",
        "    return {\"precision\":precision, \"recall\":recall, \"cer\": cer}\n",
        "\n",
        "def compute_precision(predictions=None,references=None):\n",
        "    cer_metric = load(\"cer\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for prediction, reference in zip(predictions, references):\n",
        "        correct += correctly_matched_characters(prediction, reference)\n",
        "        total += len(prediction)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "def compute_recall(predictions=None,references=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for prediction, reference in zip(predictions, references):\n",
        "        correct += correctly_matched_characters(prediction, reference)\n",
        "        total += len(reference)\n",
        "    return correct / total\n",
        "\n",
        "def correctly_matched_characters(prediction=None,reference=None):\n",
        "    correct = 0\n",
        "    prediction_shift = 0\n",
        "    reference_shift = 0\n",
        "    for i in range(len(prediction)):\n",
        "        if i+prediction_shift >= len(prediction) or i+reference_shift >= len(reference):\n",
        "          break\n",
        "        if prediction[i+prediction_shift] == reference[i+reference_shift]:\n",
        "          correct += 1\n",
        "        elif i+prediction_shift+1 < len(prediction) and prediction[i+prediction_shift+1] == reference[i+reference_shift]:\n",
        "                #deletion\n",
        "          correct += 1\n",
        "          prediction_shift +=1\n",
        "        elif i+reference_shift+1 < len(reference) and prediction[i+prediction_shift] == reference[i+reference_shift+1]:\n",
        "                #intertion\n",
        "          correct += 1\n",
        "          reference_shift +=1\n",
        "        elif i+reference_shift+1 < len(reference) and i+prediction_shift+1 < len(prediction) and prediction[i+prediction_shift+1] == reference[i+reference_shift+1]:\n",
        "                #substitution\n",
        "          correct += 1\n",
        "          prediction_shift +=1\n",
        "          reference_shift +=1\n",
        "    return correct\n",
        "# Precision = correctly matched character / number of detected character\n",
        "\n",
        "# Recall = correctly matched character / number of original characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aItHtUkXbg5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4674e5f9-9dd2-4675-fd80-2babaa4d7c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir=\"/drive/MyDrive/Comp 542/model\",\n",
        "    logging_steps=2,\n",
        "    save_steps=25,\n",
        "    eval_steps=100,\n",
        "    report_to=None,\n",
        "    fp16=True,\n",
        "    fp16_opt_level='03',\n",
        "    num_train_epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AUyvub2We1Mo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from transformers import logging as transformers_logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "transformers_logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor = TrOCRProcessor.from_pretrained('/drive/MyDrive/Comp 542/model/checkpoint-2750')\n",
        "model=VisionEncoderDecoderModel.from_pretrained('/drive/MyDrive/Comp 542/model/checkpoint-2750')\n",
        "\n",
        "eval_dataset = IAMDataset(root_dir='/drive/MyDrive/Comp 542/IAM/',df=test_df,processor=processor)"
      ],
      "metadata": {
        "id": "2kpopDLluDPH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRQrC3rxrDhd"
      },
      "outputs": [],
      "source": [
        "print(len(eval_dataset))\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    processing_class=processor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    eval_dataset=eval_dataset,)\n",
        "\n",
        "results = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ct4F9mm08QM"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame.from_dict(results,orient='index').to_csv(\"results_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhqjp5lFCv1F"
      },
      "outputs": [],
      "source": [
        "print(f\"results{results}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
